{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Optional, Tuple\n",
    "from typing_extensions import Literal\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In real world, you cannot learn how the data was generated. So do not rely on this function when coding your lab.\n",
    "def generate_data(dim, num):\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x, y, mr = generate_data(10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  8.18675439,  -8.91432283,  -9.64437179,  -5.3632507 ,\n",
       "           0.27105578, -18.27114496,   9.74313201, -17.36420999,\n",
       "          -6.66753358, -19.69042047],\n",
       "        [ -0.43298141,  22.63994361,  13.73512598,   7.13330542,\n",
       "           0.64612133,   0.2894332 ,   6.55915776, -15.42638533,\n",
       "          -2.1653315 ,  -4.10079563],\n",
       "        [ 12.33937544,  10.67572402,  -1.85524783,   5.73038023,\n",
       "         -20.55171786,   1.79383625, -11.84799447,  11.30016542,\n",
       "          -4.241219  ,  -2.1574242 ],\n",
       "        [ 13.2166369 ,  -4.25077212,   7.4872491 ,   3.94180742,\n",
       "           8.9841759 ,   4.80291812,   2.94774935,   1.32833768,\n",
       "           6.21065952,   4.69092537],\n",
       "        [-11.64980143,  -9.49323128,   3.2051567 ,  -2.62473398,\n",
       "         -17.93895094,  15.03845576, -12.8802023 ,   8.40750712,\n",
       "          14.02827372,  22.83351778]]),\n",
       " array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do anything necessary about the model\n",
    "# SGD 梯度下降法\n",
    "from optparse import Option\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class SVM1:\n",
    "    def __init__(self, dim, learning_rate:float, max_iter:int, C:float):\n",
    "        \"\"\"\n",
    "        You can add some other parameters, which I think is not necessary\n",
    "        \"\"\"\n",
    "        self.lr = learning_rate     # 学习率\n",
    "        self.max_iter = max_iter    # 最大迭代次数\n",
    "        self.C = C  # 惩罚系数\n",
    "        self.dim = dim  # 数据维度  \n",
    "\n",
    "\n",
    "    def fit(self, X:np.ndarray, y:np.ndarray, val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\n",
    "        \"\"\"\n",
    "        Fit the coefficients via your methods\n",
    "        用数据集(X,y)拟合模型, 并记录拟合过程中每个epoch的训练错误率及验证错误率(如果提供验证集val_data)\n",
    "        \"\"\"\n",
    "        self.train_data = (X, y)\n",
    "        #train_datas = np.c_[X, y]\n",
    "        self.val_data = val_data\n",
    "        X = self.__transfrom(X)\n",
    "        #print(X.shape)     X.shape = (90000,30)\n",
    "        #print(y.shape)     y.shape = (90000,1)\n",
    "        #self.w = np.zeros(X.shape[1])\n",
    "        self.w = np.zeros((1, self.dim),dtype=float)   # 初始化权重 w = 0 此时 w.shape = (1,30)\n",
    "        self.w = self.w.T   # 将 w 转置 此时 w.shape = (30,1)\n",
    "        \n",
    "        self.b = 0\n",
    "        self.err = {'train':[], 'val':[]}\n",
    "        # SGD:\n",
    "        for i in range(self.max_iter):\n",
    "            e = 1 - (np.dot(X, self.w) + self.b) * y # hinge损失 1-(WX+b)*y = 1-yf(x)\n",
    "            # print(e.shape) e.shape = (90000,1)\n",
    "            ei = (e >= 0)\n",
    "            #print(X[ei[:,0]])\n",
    "            if not ei.any():    # 如果样本的 1-(WX+b)*y < 0, 那么参数保持不变\n",
    "                break\n",
    "            delta_w = self.w - self.C * np.dot(X[ei[:,0]].T, y[ei[:,0]])  # delta_w.shape = (30,1)\n",
    "            delta_b = -self.C * np.sum(y[ei[:,0]])   \n",
    "            if np.sum(delta_w ** 2) + delta_b ** 2 < 1:\n",
    "                break\n",
    "            self.w -= self.lr * delta_w # 更新 w\n",
    "            self.b -= self.lr * delta_b # 更新 b\n",
    "            if(i % 10 == 0):\n",
    "                train_acc = self.score(X, y, metric='acc')\n",
    "                print(\"已经%d个epoch  train acc = %f\" %(i, train_acc))\n",
    "                #self.C += 1\n",
    "            self.update_err()\n",
    "\n",
    "    def __transfrom(self, X: np.ndarray):\n",
    "        return X\n",
    "\n",
    "\n",
    "    def update_err(self):\n",
    "        self.err['train'].append(self.score(self.train_data[0], self.train_data[1], 'err'))\n",
    "        if self.val_data:\n",
    "            self.err['val'].append(self.score(self.val_data[0], self.val_data[1], 'err'))\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to generate prediction probabilities on a new\n",
    "        collection of data points.\n",
    "        用训练好的模型预测X的标签\n",
    "        \"\"\"\n",
    "        X = self.__transfrom(X)\n",
    "        pred = np.sign(np.dot(X, self.w) + self.b)\n",
    "        pred[pred == 0] = 1     # >=0 的全为 1\n",
    "        return pred\n",
    "\n",
    "    def score(self, X:np.ndarray, target:np.ndarray, metric: Literal['err', 'acc', 'f1'] = 'acc'):\n",
    "        \"\"\"\n",
    "        用模型预测X的标签并与真实标签target比较, 计算评估函数值。\n",
    "        \"\"\"\n",
    "        assert(X.shape[0] == target.size)\n",
    "        if metric == 'acc' or 'err':\n",
    "            y_pred = self.predict(X)\n",
    "            acc = np.sum(y_pred == target) / target.size\n",
    "            return acc if metric == 'acc' else 1-acc\n",
    "        if metric == 'f1':\n",
    "            y_pred = self.predict(X)\n",
    "            TP = np.sum(np.logical_and(y_pred == 1, target == 1))\n",
    "            prec = TP / np.sum(y_pred == 1)\n",
    "            recall = TP / np.sum(target == 1)\n",
    "            return 2 * prec * recall / (prec + recall)\n",
    "\n",
    "    \n",
    "    def plot_boundary(self, X:np.ndarray, y:np.ndarray, sv:bool=True):\n",
    "        \"\"\"\n",
    "        绘制决策边界，支持超平面，并标出支持向量\n",
    "        \"\"\"\n",
    "        #assert X.shape[1] == 2\n",
    "        x1, x2 = X[:, 0], X[:, 1]\n",
    "        x1_lim = np.array([np.min(x1), np.max(x1)]) + np.array([-1, 1]) * .05 * np.ptp(x1)\n",
    "        x2_lim = np.array([np.min(x2), np.max(x2)]) + np.array([-1, 1]) * .05 * np.ptp(x2)\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xlim(x1_lim[0], x1_lim[1])\n",
    "        ax.set_ylim(x2_lim[0], x2_lim[1])\n",
    "        acc = self.score(X, y, 'acc')\n",
    "        ax.set_title(\"Boundary of SVM\\naccuracy={}\".format(round(acc, 3)))\n",
    "        ax.set_xlabel(\"x1\")\n",
    "        ax.set_ylabel(\"x2\")\n",
    "        x1_sample = np.linspace(np.floor(x1_lim[0]), np.ceil(x1_lim[1]), num = 100)\n",
    "\n",
    "        def get_x2_sample(y):\n",
    "            return (y - (self.b + self.w[0] * x1_sample)) / (self.w[1] + 1e-10)\n",
    "        ax.plot(x1_sample, get_x2_sample(y=0), 'r-', linewidth=1.5, label='clf plane')\n",
    "        ax.plot(x1_sample, get_x2_sample(y=1), 'r--', linewidth=1.5, label='support plane')\n",
    "        ax.plot(x1_sample, get_x2_sample(y=-1), 'r--', linewidth=1.5)\n",
    "        #print(x1[y==1])\n",
    "        yi_1 = (y == 1)\n",
    "        yi_0 = (y == -1)\n",
    "        #print(yi_0)\n",
    "        ax.scatter(x1[yi_1[:,0]], x2[yi_1[:,0]], c='#ff7f0e', label='positive')\n",
    "        ax.scatter(x1[yi_0[:,0]], x2[yi_0[:,0]], c='#e377c2', label='negative')\n",
    "        \n",
    "        if sv:\n",
    "            sv = (1 - (np.dot(X, self.w) + self.b) * y) >= 0\n",
    "            ax.scatter(x1[sv[:,0]], x2[sv[:,0]], marker='o', s=150,\n",
    "                       facecolors='none', edgecolors='#1f77b4',\n",
    "                       linewidth=2, label='support vector')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        绘制学习曲线\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title('Learning curve with lr={}'.format(self.lr))\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('error rate')\n",
    "        ax.plot(np.arange(1, len(self.err['train']) + 1), self.err['train'], label='training error')\n",
    "        if self.err['val']: \n",
    "            ax.plot(np.arange(1, len(self.err['val']) + 1), self.err['val'], label='testing error')\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do anything necessary about the model\n",
    "# 第二种方法：SMO（序列最小优化算法）我认为 SMO 也属于坐标轮换法的一种，只不过它每次选择两个坐标\n",
    "# SVM 的对偶函数具有两个约束条件，而坐标轮换法适用于求无约束条件的\n",
    "# 步骤：\n",
    "#  1. 类比坐标轮换法，每次选取两个变量 a1,a2，根据约束条件得到 a1y1 + a2y2 = -sum(aiyi) i = 3,...,n\n",
    "#  2. 由于 -sum(aiyi) i = 3,...,n 可以看成常量，可用松弛变量 E 代替，得到 a1 = (E - a2y2)y1\n",
    "#  3. 原优化函数可写为 W(a1, a2,..., an) = W((E - a2y2)y1, a2, a3,..., an)\n",
    "#  4. 因为 a3,...,an 为常数，则 W 为关于 a2 的二次函数，通过对其求导，可以得出 W 的最优解\n",
    "#     由于 a2 存在约束，则存在有上下限的问题，需要对在 W 取得最优解时的 a2 加以判断，最终更新 a2 与 a1，b 的值\n",
    "#  5. 类比坐标轮换法，在一轮结束后，判断条件 || ak^n - ak-1^n|| <= epsilon，a = (a1, a2,..., an), k 为轮数\n",
    "#     若不满足即可开启下一轮，重复步骤 2。若满足，则停止迭代，输出最优解 a* = ak^n\n",
    "# 这里我进行了简化，我选择ij不用启发式的选择，而是用最普通的随机\n",
    "\n",
    "from random import random\n",
    "\n",
    "\n",
    "class SVM2:\n",
    "    def __init__(self, dim, maxiter, C):\n",
    "        \"\"\"\n",
    "        You can add some other parameters, which I think is not necessary\n",
    "        \"\"\"\n",
    "        self.maxiter = maxiter  # 最大迭代次数\n",
    "        self.C = C  # 惩罚系数\n",
    "        self.epsilon = 1e-4\n",
    "\n",
    "    def linear_kernel(self, x1, x2):  # 表6.1（线性核）\n",
    "        return np.dot(x1, x2.T)\n",
    "\n",
    "    def getsign(self, X, w, b):\n",
    "        return np.sign(np.dot(w.T, X.T) + b).astype(int)\n",
    "\n",
    "    def calcE(self, x, y, w, b):\n",
    "        return self.getsign(x, w, b) - y\n",
    "\n",
    "    def fit(self, X, y, val_data: Optional[Tuple[np.ndarray, np.ndarray]]):\n",
    "        \"\"\"\n",
    "        Fit the coefficients via your methods\n",
    "        \"\"\"\n",
    "        self.train_data = (X, y)\n",
    "        self.val_data = val_data\n",
    "        # X是数据空间，y是标签\n",
    "        n = X.shape[0]  # n是数据个数,多少行\n",
    "        d = X.shape[1]  # d是数据维度,多少列\n",
    "        # print(y.shape)\n",
    "        # print(X.shape)\n",
    "        curiter = 0\n",
    "        self.w = np.zeros((20,1))\n",
    "        self.b = 0\n",
    "        alpha = np.zeros((n, 1))  # 拉格朗日乘子\n",
    "        self.err = {'train':[], 'val':[]}\n",
    "        for curiter in range(self.maxiter):\n",
    "            self.update_err()\n",
    "            if  curiter != 0:\n",
    "                # train_acc = self.score(X, y, metric='acc')\n",
    "                y_pred = self.predict(X)\n",
    "                acc = np.sum(y_pred == y) / n\n",
    "                print(\"已经%d个epoch, train_acc=%f\"%(curiter, acc))\n",
    "\n",
    "            innercnt = 0\n",
    "            cnt = 0\n",
    "            for cnt in range(n):\n",
    "                # 选取一对需更新的变量ai和aj\n",
    "                # 我们没有采用启发式的方法，而是转用更简单的随机选择，这样会使程序运行效率降低\n",
    "                i = np.random.randint(0, n)\n",
    "                j = np.random.randint(0, n)\n",
    "                # print(i,j)\n",
    "                if(i == j): # 选择与 ai 不同的向量 aj\n",
    "                    continue\n",
    "                innercnt += 1\n",
    "                x_i, x_j, y_i, y_j = X[i, :], X[j, :], y[i], y[j]\n",
    "                # print(y[j])\n",
    "                # print(x_i)  no problem\n",
    "                # print(y_i)\n",
    "\n",
    "                # 计算上下界\n",
    "                k_ij = self.linear_kernel(x_i, x_i) + self.linear_kernel(x_j, x_j) - 2 * self.linear_kernel(x_i, x_j)\n",
    "                prei = alpha[i] # 初始化是 0\n",
    "                prej = alpha[j]\n",
    "                # print(k_ij) no problem\n",
    "\n",
    "                # 计算此时的w和b\n",
    "                self.w = np.dot(X.T, np.multiply(alpha, y))\n",
    "                self.b = np.mean(y - np.dot(self.w.T, X.T)) # b 是所有支持向量求解的平均值\n",
    "                # print(self.w)  no problem\n",
    "                # print(self.b)  no problem\n",
    "                # print(self.w, self.b) no problem\n",
    "                # print(np.sign(np.dot(self.w.T, x_i.T) + self.b) - y_i ) no problem\n",
    "\n",
    "                # 计算差值(error)  规范的smo这一步应该前置，便于我们启发式的选择j变量\n",
    "                # print(self.getsign(X, self.w, self.b))\n",
    "                # print(y_i)\n",
    "                E_i = self.calcE(x_i, y_i, self.w, self.b)\n",
    "                E_j = self.calcE(x_j, y_j, self.w, self.b)\n",
    "                # print(E_i)\n",
    "                # print(E_i, E_j)\n",
    "\n",
    "                # 更新拉格朗日参数\n",
    "                alpha[j] = prej + float(y_j * (E_i - E_j)) / k_ij\n",
    "                alpha[j] = min(1, max(alpha[j], 0))\n",
    "                alpha[i] = prei + y_i*y_j * (prej - alpha[j])\n",
    "                # print(alpha[j])   no problem\n",
    "                # print(alpha[i])   no problem\n",
    "                # print(prei, prej)\n",
    "                # print(alpha[i], alpha[j])\n",
    "\n",
    "                # 判断是否达到终止条件\n",
    "                # print(abs(prei-alpha[i]) + abs(prej-alpha[j]))\n",
    "                if(abs(prei-alpha[i]) + abs(prej-alpha[j]) < self.epsilon):\n",
    "                    break\n",
    "\n",
    "    def update_err(self):\n",
    "        self.err['train'].append(self.score(self.train_data[0], self.train_data[1], 'err'))\n",
    "        if self.val_data:\n",
    "            self.err['val'].append(self.score(self.val_data[0], self.val_data[1], 'err'))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to generate prediction probabilities on a new\n",
    "        collection of data points.\n",
    "        \"\"\"\n",
    "        return self.getsign(X, self.w, self.b).T\n",
    "\n",
    "    def score(self, X:np.ndarray, target:np.ndarray, metric: Literal['err', 'acc', 'f1'] = 'acc'):\n",
    "        \"\"\"\n",
    "        用模型预测X的标签并与真实标签target比较, 计算评估函数值。\n",
    "        \"\"\"\n",
    "        assert(X.shape[0] == target.size)\n",
    "        if metric == 'acc' or 'err':\n",
    "            y_pred = self.predict(X)\n",
    "            acc = np.sum(y_pred == target) / target.size\n",
    "            return acc if metric == 'acc' else 1-acc\n",
    "        \n",
    "\n",
    "    def plot_learning_curve(self):\n",
    "        \"\"\"\n",
    "        绘制学习曲线\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title('Learning curve ')\n",
    "        ax.set_xlabel('epoch')\n",
    "        ax.set_ylabel('error rate')\n",
    "        ax.plot(np.arange(1, len(self.err['train']) + 1), self.err['train'], label='training error')\n",
    "        if self.err['val']: \n",
    "            ax.plot(np.arange(1, len(self.err['val']) + 1), self.err['val'], label='testing error')\n",
    "        ax.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and train your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and compare your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法 1：梯度下降（跑完大概需要 30 s）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经0个epoch  train acc = 0.959922\n",
      "已经10个epoch  train acc = 0.963022\n",
      "已经20个epoch  train acc = 0.963122\n",
      "已经30个epoch  train acc = 0.963044\n",
      "已经40个epoch  train acc = 0.963111\n",
      "已经50个epoch  train acc = 0.963078\n",
      "已经60个epoch  train acc = 0.797322\n",
      "已经70个epoch  train acc = 0.950233\n",
      "已经80个epoch  train acc = 0.928178\n",
      "已经90个epoch  train acc = 0.867133\n",
      "已经100个epoch  train acc = 0.923922\n",
      "已经110个epoch  train acc = 0.916411\n",
      "已经120个epoch  train acc = 0.888311\n",
      "已经130个epoch  train acc = 0.901067\n",
      "已经140个epoch  train acc = 0.909744\n",
      "已经150个epoch  train acc = 0.901522\n",
      "已经160个epoch  train acc = 0.900378\n",
      "已经170个epoch  train acc = 0.904144\n",
      "已经180个epoch  train acc = 0.901978\n",
      "已经190个epoch  train acc = 0.902478\n",
      "已经200个epoch  train acc = 0.902533\n",
      "已经210个epoch  train acc = 0.902478\n",
      "已经220个epoch  train acc = 0.902422\n",
      "已经230个epoch  train acc = 0.902533\n",
      "已经240个epoch  train acc = 0.902467\n",
      "已经250个epoch  train acc = 0.902533\n",
      "已经260个epoch  train acc = 0.902444\n",
      "已经270个epoch  train acc = 0.902422\n",
      "已经280个epoch  train acc = 0.902489\n",
      "已经290个epoch  train acc = 0.902467\n",
      "已经300个epoch  train acc = 0.902489\n",
      "已经310个epoch  train acc = 0.902478\n",
      "已经320个epoch  train acc = 0.902433\n",
      "已经330个epoch  train acc = 0.902522\n",
      "已经340个epoch  train acc = 0.902422\n",
      "已经350个epoch  train acc = 0.902478\n",
      "已经360个epoch  train acc = 0.902511\n",
      "已经370个epoch  train acc = 0.902400\n",
      "已经380个epoch  train acc = 0.902511\n",
      "已经390个epoch  train acc = 0.902389\n",
      "已经400个epoch  train acc = 0.902489\n",
      "已经410个epoch  train acc = 0.902456\n",
      "已经420个epoch  train acc = 0.902589\n",
      "已经430个epoch  train acc = 0.902544\n",
      "已经440个epoch  train acc = 0.902422\n",
      "已经450个epoch  train acc = 0.902411\n",
      "已经460个epoch  train acc = 0.902400\n",
      "已经470个epoch  train acc = 0.902533\n",
      "已经480个epoch  train acc = 0.902422\n",
      "已经490个epoch  train acc = 0.902456\n",
      "train acc = 0.9025\n",
      "test acc = 0.9023902390239024\n",
      "错误率曲线如下：\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate data\n",
    "X_data, y_data, mislabel = generate_data(20, 100000) \n",
    "\n",
    "# split data\n",
    "X_train = X_data[0:90000]\n",
    "y_train = y_data[0:90000]\n",
    "X_test = X_data[90001:]\n",
    "y_test = y_data[90001:]\n",
    "\n",
    "# constrcut model and train (remember record time)\n",
    "model1 = SVM1(20, learning_rate=0.001, max_iter=500, C=1)\n",
    "model1.fit(X_train, y_train, val_data=(X_test, y_test)) \n",
    "# model1.fit()\n",
    "# make prediction\n",
    "# pred = model1.predict()\n",
    "\n",
    "# predict and calculate acc\n",
    "train_acc = model1.score(X_train, y_train, metric='acc')\n",
    "test_acc = model1.score(X_test, y_test, metric='acc')\n",
    "print(\"train acc = {0}\".format(train_acc))\n",
    "print(\"test acc = {0}\".format(test_acc))\n",
    "\n",
    "# plot learning curve and decision boundary\n",
    "# 如果是高维度决策图是没有意义的，这里我只是尝试在 2 维的情况下绘制\n",
    "print(\"错误率曲线如下：\")\n",
    "model1.plot_learning_curve()\n",
    "# model1.plot_boundary(X_train, y_train, sv=True)\n",
    "# model1.plot_boundary(X_test, y_test, sv=False)\n",
    "\n",
    "# compared with answer\n",
    "\n",
    "# compare each methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法 2：SMO（跑完大概需要 5 min）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已经1个epoch, train_acc=0.500778\n",
      "已经2个epoch, train_acc=0.500778\n",
      "已经3个epoch, train_acc=0.561000\n",
      "已经4个epoch, train_acc=0.561000\n",
      "已经5个epoch, train_acc=0.609000\n",
      "已经6个epoch, train_acc=0.609000\n",
      "已经7个epoch, train_acc=0.609000\n",
      "已经8个epoch, train_acc=0.609000\n",
      "已经9个epoch, train_acc=0.609000\n",
      "已经10个epoch, train_acc=0.609000\n",
      "已经11个epoch, train_acc=0.624667\n",
      "已经12个epoch, train_acc=0.624667\n",
      "已经13个epoch, train_acc=0.655778\n",
      "已经14个epoch, train_acc=0.647556\n",
      "已经15个epoch, train_acc=0.647556\n",
      "已经16个epoch, train_acc=0.680889\n",
      "已经17个epoch, train_acc=0.674889\n",
      "已经18个epoch, train_acc=0.698556\n",
      "已经19个epoch, train_acc=0.716333\n",
      "已经20个epoch, train_acc=0.716333\n",
      "已经21个epoch, train_acc=0.716333\n",
      "已经22个epoch, train_acc=0.742111\n",
      "已经23个epoch, train_acc=0.724444\n",
      "已经24个epoch, train_acc=0.739222\n",
      "已经25个epoch, train_acc=0.739222\n",
      "已经26个epoch, train_acc=0.739222\n",
      "已经27个epoch, train_acc=0.739222\n",
      "已经28个epoch, train_acc=0.744667\n",
      "已经29个epoch, train_acc=0.744667\n",
      "已经30个epoch, train_acc=0.744667\n",
      "已经31个epoch, train_acc=0.778889\n",
      "已经32个epoch, train_acc=0.794889\n",
      "已经33个epoch, train_acc=0.799444\n",
      "已经34个epoch, train_acc=0.799444\n",
      "已经35个epoch, train_acc=0.799444\n",
      "已经36个epoch, train_acc=0.799444\n",
      "已经37个epoch, train_acc=0.799444\n",
      "已经38个epoch, train_acc=0.803333\n",
      "已经39个epoch, train_acc=0.803333\n",
      "已经40个epoch, train_acc=0.803333\n",
      "已经41个epoch, train_acc=0.803333\n",
      "已经42个epoch, train_acc=0.803333\n",
      "已经43个epoch, train_acc=0.803333\n",
      "已经44个epoch, train_acc=0.803333\n",
      "已经45个epoch, train_acc=0.803333\n",
      "已经46个epoch, train_acc=0.803333\n",
      "已经47个epoch, train_acc=0.803333\n",
      "已经48个epoch, train_acc=0.803333\n",
      "已经49个epoch, train_acc=0.780556\n",
      "已经50个epoch, train_acc=0.780556\n",
      "已经51个epoch, train_acc=0.780556\n",
      "已经52个epoch, train_acc=0.780556\n",
      "已经53个epoch, train_acc=0.780556\n",
      "已经54个epoch, train_acc=0.806444\n",
      "已经55个epoch, train_acc=0.806444\n",
      "已经56个epoch, train_acc=0.806444\n",
      "已经57个epoch, train_acc=0.806444\n",
      "已经58个epoch, train_acc=0.780889\n",
      "已经59个epoch, train_acc=0.798444\n",
      "已经60个epoch, train_acc=0.798444\n",
      "已经61个epoch, train_acc=0.798444\n",
      "已经62个epoch, train_acc=0.798444\n",
      "已经63个epoch, train_acc=0.813000\n",
      "已经64个epoch, train_acc=0.811889\n",
      "已经65个epoch, train_acc=0.811889\n",
      "已经66个epoch, train_acc=0.811889\n",
      "已经67个epoch, train_acc=0.811889\n",
      "已经68个epoch, train_acc=0.811889\n",
      "已经69个epoch, train_acc=0.811889\n",
      "已经70个epoch, train_acc=0.800111\n",
      "已经71个epoch, train_acc=0.797667\n",
      "已经72个epoch, train_acc=0.797667\n",
      "已经73个epoch, train_acc=0.785778\n",
      "已经74个epoch, train_acc=0.785778\n",
      "已经75个epoch, train_acc=0.785778\n",
      "已经76个epoch, train_acc=0.773222\n",
      "已经77个epoch, train_acc=0.784556\n",
      "已经78个epoch, train_acc=0.776000\n",
      "已经79个epoch, train_acc=0.776000\n",
      "已经80个epoch, train_acc=0.776000\n",
      "已经81个epoch, train_acc=0.776000\n",
      "已经82个epoch, train_acc=0.776000\n",
      "已经83个epoch, train_acc=0.776000\n",
      "已经84个epoch, train_acc=0.776000\n",
      "已经85个epoch, train_acc=0.776000\n",
      "已经86个epoch, train_acc=0.776000\n",
      "已经87个epoch, train_acc=0.786333\n",
      "已经88个epoch, train_acc=0.787444\n",
      "已经89个epoch, train_acc=0.787444\n",
      "已经90个epoch, train_acc=0.796444\n",
      "已经91个epoch, train_acc=0.796444\n",
      "已经92个epoch, train_acc=0.791778\n",
      "已经93个epoch, train_acc=0.791778\n",
      "已经94个epoch, train_acc=0.791778\n",
      "已经95个epoch, train_acc=0.796778\n",
      "已经96个epoch, train_acc=0.796778\n",
      "已经97个epoch, train_acc=0.808111\n",
      "已经98个epoch, train_acc=0.827333\n",
      "已经99个epoch, train_acc=0.827333\n",
      "已经100个epoch, train_acc=0.827333\n",
      "已经101个epoch, train_acc=0.840222\n",
      "已经102个epoch, train_acc=0.846889\n",
      "已经103个epoch, train_acc=0.839222\n",
      "已经104个epoch, train_acc=0.839222\n",
      "已经105个epoch, train_acc=0.839222\n",
      "已经106个epoch, train_acc=0.839222\n",
      "已经107个epoch, train_acc=0.839222\n",
      "已经108个epoch, train_acc=0.834889\n",
      "已经109个epoch, train_acc=0.834889\n",
      "已经110个epoch, train_acc=0.834889\n",
      "已经111个epoch, train_acc=0.834889\n",
      "已经112个epoch, train_acc=0.834889\n",
      "已经113个epoch, train_acc=0.834889\n",
      "已经114个epoch, train_acc=0.834889\n",
      "已经115个epoch, train_acc=0.834889\n",
      "已经116个epoch, train_acc=0.841444\n",
      "已经117个epoch, train_acc=0.841444\n",
      "已经118个epoch, train_acc=0.841444\n",
      "已经119个epoch, train_acc=0.841444\n",
      "已经120个epoch, train_acc=0.848444\n",
      "已经121个epoch, train_acc=0.848444\n",
      "已经122个epoch, train_acc=0.859556\n",
      "已经123个epoch, train_acc=0.859556\n",
      "已经124个epoch, train_acc=0.850111\n",
      "已经125个epoch, train_acc=0.850111\n",
      "已经126个epoch, train_acc=0.850111\n",
      "已经127个epoch, train_acc=0.850111\n",
      "已经128个epoch, train_acc=0.851667\n",
      "已经129个epoch, train_acc=0.851667\n",
      "已经130个epoch, train_acc=0.851667\n",
      "已经131个epoch, train_acc=0.851667\n",
      "已经132个epoch, train_acc=0.851667\n",
      "已经133个epoch, train_acc=0.851667\n",
      "已经134个epoch, train_acc=0.836333\n",
      "已经135个epoch, train_acc=0.836333\n",
      "已经136个epoch, train_acc=0.836333\n",
      "已经137个epoch, train_acc=0.836333\n",
      "已经138个epoch, train_acc=0.836333\n",
      "已经139个epoch, train_acc=0.836333\n",
      "已经140个epoch, train_acc=0.836333\n",
      "已经141个epoch, train_acc=0.829444\n",
      "已经142个epoch, train_acc=0.829444\n",
      "已经143个epoch, train_acc=0.829444\n",
      "已经144个epoch, train_acc=0.829444\n",
      "已经145个epoch, train_acc=0.829444\n",
      "已经146个epoch, train_acc=0.829444\n",
      "已经147个epoch, train_acc=0.829444\n",
      "已经148个epoch, train_acc=0.829444\n",
      "已经149个epoch, train_acc=0.829556\n",
      "已经150个epoch, train_acc=0.829556\n",
      "已经151个epoch, train_acc=0.841556\n",
      "已经152个epoch, train_acc=0.841556\n",
      "已经153个epoch, train_acc=0.841556\n",
      "已经154个epoch, train_acc=0.841556\n",
      "已经155个epoch, train_acc=0.853333\n",
      "已经156个epoch, train_acc=0.851556\n",
      "已经157个epoch, train_acc=0.851556\n",
      "已经158个epoch, train_acc=0.851556\n",
      "已经159个epoch, train_acc=0.851556\n",
      "已经160个epoch, train_acc=0.851556\n",
      "已经161个epoch, train_acc=0.851556\n",
      "已经162个epoch, train_acc=0.851556\n",
      "已经163个epoch, train_acc=0.851556\n",
      "已经164个epoch, train_acc=0.871222\n",
      "已经165个epoch, train_acc=0.871222\n",
      "已经166个epoch, train_acc=0.871222\n",
      "已经167个epoch, train_acc=0.871222\n",
      "已经168个epoch, train_acc=0.871222\n",
      "已经169个epoch, train_acc=0.871222\n",
      "已经170个epoch, train_acc=0.870778\n",
      "已经171个epoch, train_acc=0.870778\n",
      "已经172个epoch, train_acc=0.851778\n",
      "已经173个epoch, train_acc=0.851778\n",
      "已经174个epoch, train_acc=0.839222\n",
      "已经175个epoch, train_acc=0.832778\n",
      "已经176个epoch, train_acc=0.832778\n",
      "已经177个epoch, train_acc=0.832778\n",
      "已经178个epoch, train_acc=0.824000\n",
      "已经179个epoch, train_acc=0.824000\n",
      "已经180个epoch, train_acc=0.824000\n",
      "已经181个epoch, train_acc=0.824000\n",
      "已经182个epoch, train_acc=0.824000\n",
      "已经183个epoch, train_acc=0.824000\n",
      "已经184个epoch, train_acc=0.824000\n",
      "已经185个epoch, train_acc=0.824000\n",
      "已经186个epoch, train_acc=0.824000\n",
      "已经187个epoch, train_acc=0.824000\n",
      "已经188个epoch, train_acc=0.824000\n",
      "已经189个epoch, train_acc=0.824000\n",
      "已经190个epoch, train_acc=0.817556\n",
      "已经191个epoch, train_acc=0.817556\n",
      "已经192个epoch, train_acc=0.817556\n",
      "已经193个epoch, train_acc=0.817556\n",
      "已经194个epoch, train_acc=0.817556\n",
      "已经195个epoch, train_acc=0.817556\n",
      "已经196个epoch, train_acc=0.817556\n",
      "已经197个epoch, train_acc=0.817556\n",
      "已经198个epoch, train_acc=0.817556\n",
      "已经199个epoch, train_acc=0.817556\n",
      "已经200个epoch, train_acc=0.810778\n",
      "已经201个epoch, train_acc=0.810778\n",
      "已经202个epoch, train_acc=0.810778\n",
      "已经203个epoch, train_acc=0.810778\n",
      "已经204个epoch, train_acc=0.810778\n",
      "已经205个epoch, train_acc=0.810778\n",
      "已经206个epoch, train_acc=0.810778\n",
      "已经207个epoch, train_acc=0.810778\n",
      "已经208个epoch, train_acc=0.810778\n",
      "已经209个epoch, train_acc=0.810778\n",
      "已经210个epoch, train_acc=0.810778\n",
      "已经211个epoch, train_acc=0.812111\n",
      "已经212个epoch, train_acc=0.812111\n",
      "已经213个epoch, train_acc=0.812111\n",
      "已经214个epoch, train_acc=0.811111\n",
      "已经215个epoch, train_acc=0.811111\n",
      "已经216个epoch, train_acc=0.811111\n",
      "已经217个epoch, train_acc=0.811111\n",
      "已经218个epoch, train_acc=0.811111\n",
      "已经219个epoch, train_acc=0.811111\n",
      "已经220个epoch, train_acc=0.826778\n",
      "已经221个epoch, train_acc=0.826778\n",
      "已经222个epoch, train_acc=0.826778\n",
      "已经223个epoch, train_acc=0.826778\n",
      "已经224个epoch, train_acc=0.826778\n",
      "已经225个epoch, train_acc=0.826778\n",
      "已经226个epoch, train_acc=0.826778\n",
      "已经227个epoch, train_acc=0.826778\n",
      "已经228个epoch, train_acc=0.826778\n",
      "已经229个epoch, train_acc=0.826778\n",
      "已经230个epoch, train_acc=0.826778\n",
      "已经231个epoch, train_acc=0.826778\n",
      "已经232个epoch, train_acc=0.826778\n",
      "已经233个epoch, train_acc=0.826778\n",
      "已经234个epoch, train_acc=0.829222\n",
      "已经235个epoch, train_acc=0.829222\n",
      "已经236个epoch, train_acc=0.829222\n",
      "已经237个epoch, train_acc=0.825889\n",
      "已经238个epoch, train_acc=0.825889\n",
      "已经239个epoch, train_acc=0.830333\n",
      "已经240个epoch, train_acc=0.851111\n",
      "已经241个epoch, train_acc=0.851111\n",
      "已经242个epoch, train_acc=0.851111\n",
      "已经243个epoch, train_acc=0.851111\n",
      "已经244个epoch, train_acc=0.834222\n",
      "已经245个epoch, train_acc=0.834222\n",
      "已经246个epoch, train_acc=0.837778\n",
      "已经247个epoch, train_acc=0.837778\n",
      "已经248个epoch, train_acc=0.837778\n",
      "已经249个epoch, train_acc=0.837778\n",
      "已经250个epoch, train_acc=0.837778\n",
      "已经251个epoch, train_acc=0.837778\n",
      "已经252个epoch, train_acc=0.837778\n",
      "已经253个epoch, train_acc=0.837778\n",
      "已经254个epoch, train_acc=0.837778\n",
      "已经255个epoch, train_acc=0.837778\n",
      "已经256个epoch, train_acc=0.837778\n",
      "已经257个epoch, train_acc=0.837778\n",
      "已经258个epoch, train_acc=0.837778\n",
      "已经259个epoch, train_acc=0.837778\n",
      "已经260个epoch, train_acc=0.837778\n",
      "已经261个epoch, train_acc=0.837778\n",
      "已经262个epoch, train_acc=0.837778\n",
      "已经263个epoch, train_acc=0.837778\n",
      "已经264个epoch, train_acc=0.840444\n",
      "已经265个epoch, train_acc=0.840444\n",
      "已经266个epoch, train_acc=0.840444\n",
      "已经267个epoch, train_acc=0.854667\n",
      "已经268个epoch, train_acc=0.854667\n",
      "已经269个epoch, train_acc=0.854667\n",
      "已经270个epoch, train_acc=0.854667\n",
      "已经271个epoch, train_acc=0.854667\n",
      "已经272个epoch, train_acc=0.854667\n",
      "已经273个epoch, train_acc=0.854667\n",
      "已经274个epoch, train_acc=0.854667\n",
      "已经275个epoch, train_acc=0.854667\n",
      "已经276个epoch, train_acc=0.857111\n",
      "已经277个epoch, train_acc=0.857111\n",
      "已经278个epoch, train_acc=0.857111\n",
      "已经279个epoch, train_acc=0.868667\n",
      "已经280个epoch, train_acc=0.868667\n",
      "已经281个epoch, train_acc=0.868667\n",
      "已经282个epoch, train_acc=0.868667\n",
      "已经283个epoch, train_acc=0.868667\n",
      "已经284个epoch, train_acc=0.846444\n",
      "已经285个epoch, train_acc=0.849778\n",
      "已经286个epoch, train_acc=0.860778\n",
      "已经287个epoch, train_acc=0.860778\n",
      "已经288个epoch, train_acc=0.860778\n",
      "已经289个epoch, train_acc=0.860778\n",
      "已经290个epoch, train_acc=0.860778\n",
      "已经291个epoch, train_acc=0.860778\n",
      "已经292个epoch, train_acc=0.860778\n",
      "已经293个epoch, train_acc=0.860778\n",
      "已经294个epoch, train_acc=0.860778\n",
      "已经295个epoch, train_acc=0.860778\n",
      "已经296个epoch, train_acc=0.860778\n",
      "已经297个epoch, train_acc=0.860778\n",
      "已经298个epoch, train_acc=0.860778\n",
      "已经299个epoch, train_acc=0.860778\n",
      "已经300个epoch, train_acc=0.860778\n",
      "已经301个epoch, train_acc=0.860778\n",
      "已经302个epoch, train_acc=0.860778\n",
      "已经303个epoch, train_acc=0.860778\n",
      "已经304个epoch, train_acc=0.860778\n",
      "已经305个epoch, train_acc=0.860778\n",
      "已经306个epoch, train_acc=0.857000\n",
      "已经307个epoch, train_acc=0.857000\n",
      "已经308个epoch, train_acc=0.857000\n",
      "已经309个epoch, train_acc=0.857000\n",
      "已经310个epoch, train_acc=0.857000\n",
      "已经311个epoch, train_acc=0.857000\n",
      "已经312个epoch, train_acc=0.861556\n",
      "已经313个epoch, train_acc=0.860222\n",
      "已经314个epoch, train_acc=0.860222\n",
      "已经315个epoch, train_acc=0.860222\n",
      "已经316个epoch, train_acc=0.860222\n",
      "已经317个epoch, train_acc=0.860222\n",
      "已经318个epoch, train_acc=0.860222\n",
      "已经319个epoch, train_acc=0.860222\n",
      "已经320个epoch, train_acc=0.860222\n",
      "已经321个epoch, train_acc=0.860222\n",
      "已经322个epoch, train_acc=0.860222\n",
      "已经323个epoch, train_acc=0.860222\n",
      "已经324个epoch, train_acc=0.860222\n",
      "已经325个epoch, train_acc=0.860222\n",
      "已经326个epoch, train_acc=0.860222\n",
      "已经327个epoch, train_acc=0.860222\n",
      "已经328个epoch, train_acc=0.860222\n",
      "已经329个epoch, train_acc=0.860222\n",
      "已经330个epoch, train_acc=0.860222\n",
      "已经331个epoch, train_acc=0.860222\n",
      "已经332个epoch, train_acc=0.870667\n",
      "已经333个epoch, train_acc=0.870667\n",
      "已经334个epoch, train_acc=0.870667\n",
      "已经335个epoch, train_acc=0.880111\n",
      "已经336个epoch, train_acc=0.880111\n",
      "已经337个epoch, train_acc=0.880111\n",
      "已经338个epoch, train_acc=0.880111\n",
      "已经339个epoch, train_acc=0.880111\n",
      "已经340个epoch, train_acc=0.880111\n",
      "已经341个epoch, train_acc=0.880111\n",
      "已经342个epoch, train_acc=0.880111\n",
      "已经343个epoch, train_acc=0.885444\n",
      "已经344个epoch, train_acc=0.885444\n",
      "已经345个epoch, train_acc=0.885444\n",
      "已经346个epoch, train_acc=0.885444\n",
      "已经347个epoch, train_acc=0.885444\n",
      "已经348个epoch, train_acc=0.885444\n",
      "已经349个epoch, train_acc=0.885444\n",
      "已经350个epoch, train_acc=0.885444\n",
      "已经351个epoch, train_acc=0.885444\n",
      "已经352个epoch, train_acc=0.885444\n",
      "已经353个epoch, train_acc=0.885444\n",
      "已经354个epoch, train_acc=0.885444\n",
      "已经355个epoch, train_acc=0.885444\n",
      "已经356个epoch, train_acc=0.892667\n",
      "已经357个epoch, train_acc=0.892667\n",
      "已经358个epoch, train_acc=0.892667\n",
      "已经359个epoch, train_acc=0.892667\n",
      "已经360个epoch, train_acc=0.896778\n",
      "已经361个epoch, train_acc=0.896778\n",
      "已经362个epoch, train_acc=0.896778\n",
      "已经363个epoch, train_acc=0.896778\n",
      "已经364个epoch, train_acc=0.896778\n",
      "已经365个epoch, train_acc=0.896778\n",
      "已经366个epoch, train_acc=0.896778\n",
      "已经367个epoch, train_acc=0.896778\n",
      "已经368个epoch, train_acc=0.896778\n",
      "已经369个epoch, train_acc=0.896778\n",
      "已经370个epoch, train_acc=0.896778\n",
      "已经371个epoch, train_acc=0.896444\n",
      "已经372个epoch, train_acc=0.896444\n",
      "已经373个epoch, train_acc=0.868778\n",
      "已经374个epoch, train_acc=0.868778\n",
      "已经375个epoch, train_acc=0.868778\n",
      "已经376个epoch, train_acc=0.868778\n",
      "已经377个epoch, train_acc=0.871000\n",
      "已经378个epoch, train_acc=0.871000\n",
      "已经379个epoch, train_acc=0.871000\n",
      "已经380个epoch, train_acc=0.871000\n",
      "已经381个epoch, train_acc=0.871000\n",
      "已经382个epoch, train_acc=0.871000\n",
      "已经383个epoch, train_acc=0.871000\n",
      "已经384个epoch, train_acc=0.871000\n",
      "已经385个epoch, train_acc=0.871000\n",
      "已经386个epoch, train_acc=0.871000\n",
      "已经387个epoch, train_acc=0.871000\n",
      "已经388个epoch, train_acc=0.862222\n",
      "已经389个epoch, train_acc=0.862222\n",
      "已经390个epoch, train_acc=0.862222\n",
      "已经391个epoch, train_acc=0.862222\n",
      "已经392个epoch, train_acc=0.862222\n",
      "已经393个epoch, train_acc=0.862222\n",
      "已经394个epoch, train_acc=0.862222\n",
      "已经395个epoch, train_acc=0.862222\n",
      "已经396个epoch, train_acc=0.862222\n",
      "已经397个epoch, train_acc=0.862222\n",
      "已经398个epoch, train_acc=0.862222\n",
      "已经399个epoch, train_acc=0.862222\n",
      "已经400个epoch, train_acc=0.862222\n",
      "已经401个epoch, train_acc=0.857444\n",
      "已经402个epoch, train_acc=0.857444\n",
      "已经403个epoch, train_acc=0.855556\n",
      "已经404个epoch, train_acc=0.855556\n",
      "已经405个epoch, train_acc=0.871111\n",
      "已经406个epoch, train_acc=0.871111\n",
      "已经407个epoch, train_acc=0.871111\n",
      "已经408个epoch, train_acc=0.871111\n",
      "已经409个epoch, train_acc=0.871111\n",
      "已经410个epoch, train_acc=0.871111\n",
      "已经411个epoch, train_acc=0.871111\n",
      "已经412个epoch, train_acc=0.863333\n",
      "已经413个epoch, train_acc=0.867889\n",
      "已经414个epoch, train_acc=0.867889\n",
      "已经415个epoch, train_acc=0.867889\n",
      "已经416个epoch, train_acc=0.867889\n",
      "已经417个epoch, train_acc=0.867889\n",
      "已经418个epoch, train_acc=0.867889\n",
      "已经419个epoch, train_acc=0.870778\n",
      "已经420个epoch, train_acc=0.870778\n",
      "已经421个epoch, train_acc=0.870778\n",
      "已经422个epoch, train_acc=0.870778\n",
      "已经423个epoch, train_acc=0.870778\n",
      "已经424个epoch, train_acc=0.880444\n",
      "已经425个epoch, train_acc=0.880444\n",
      "已经426个epoch, train_acc=0.880444\n",
      "已经427个epoch, train_acc=0.880444\n",
      "已经428个epoch, train_acc=0.880444\n",
      "已经429个epoch, train_acc=0.880444\n",
      "已经430个epoch, train_acc=0.880444\n",
      "已经431个epoch, train_acc=0.880444\n",
      "已经432个epoch, train_acc=0.880444\n",
      "已经433个epoch, train_acc=0.880444\n",
      "已经434个epoch, train_acc=0.880444\n",
      "已经435个epoch, train_acc=0.880444\n",
      "已经436个epoch, train_acc=0.886333\n",
      "已经437个epoch, train_acc=0.886333\n",
      "已经438个epoch, train_acc=0.886333\n",
      "已经439个epoch, train_acc=0.881444\n",
      "已经440个epoch, train_acc=0.881444\n",
      "已经441个epoch, train_acc=0.881444\n",
      "已经442个epoch, train_acc=0.881444\n",
      "已经443个epoch, train_acc=0.881444\n",
      "已经444个epoch, train_acc=0.881444\n",
      "已经445个epoch, train_acc=0.881444\n",
      "已经446个epoch, train_acc=0.881444\n",
      "已经447个epoch, train_acc=0.881444\n",
      "已经448个epoch, train_acc=0.881444\n",
      "已经449个epoch, train_acc=0.881444\n",
      "已经450个epoch, train_acc=0.881444\n",
      "已经451个epoch, train_acc=0.881444\n",
      "已经452个epoch, train_acc=0.881444\n",
      "已经453个epoch, train_acc=0.881444\n",
      "已经454个epoch, train_acc=0.885222\n",
      "已经455个epoch, train_acc=0.885222\n",
      "已经456个epoch, train_acc=0.888333\n",
      "已经457个epoch, train_acc=0.883222\n",
      "已经458个epoch, train_acc=0.883222\n",
      "已经459个epoch, train_acc=0.883222\n",
      "已经460个epoch, train_acc=0.881222\n",
      "已经461个epoch, train_acc=0.881667\n",
      "已经462个epoch, train_acc=0.881667\n",
      "已经463个epoch, train_acc=0.881667\n",
      "已经464个epoch, train_acc=0.881667\n",
      "已经465个epoch, train_acc=0.875667\n",
      "已经466个epoch, train_acc=0.875667\n",
      "已经467个epoch, train_acc=0.881667\n",
      "已经468个epoch, train_acc=0.881667\n",
      "已经469个epoch, train_acc=0.881667\n",
      "已经470个epoch, train_acc=0.881667\n",
      "已经471个epoch, train_acc=0.890333\n",
      "已经472个epoch, train_acc=0.890333\n",
      "已经473个epoch, train_acc=0.890333\n",
      "已经474个epoch, train_acc=0.890333\n",
      "已经475个epoch, train_acc=0.890333\n",
      "已经476个epoch, train_acc=0.890333\n",
      "已经477个epoch, train_acc=0.890333\n",
      "已经478个epoch, train_acc=0.890333\n",
      "已经479个epoch, train_acc=0.890333\n",
      "已经480个epoch, train_acc=0.890333\n",
      "已经481个epoch, train_acc=0.887889\n",
      "已经482个epoch, train_acc=0.887889\n",
      "已经483个epoch, train_acc=0.887889\n",
      "已经484个epoch, train_acc=0.887889\n",
      "已经485个epoch, train_acc=0.887889\n",
      "已经486个epoch, train_acc=0.887889\n",
      "已经487个epoch, train_acc=0.887889\n",
      "已经488个epoch, train_acc=0.887889\n",
      "已经489个epoch, train_acc=0.887889\n",
      "已经490个epoch, train_acc=0.887889\n",
      "已经491个epoch, train_acc=0.887889\n",
      "已经492个epoch, train_acc=0.887889\n",
      "已经493个epoch, train_acc=0.887889\n",
      "已经494个epoch, train_acc=0.871778\n",
      "已经495个epoch, train_acc=0.871778\n",
      "已经496个epoch, train_acc=0.871778\n",
      "已经497个epoch, train_acc=0.871778\n",
      "已经498个epoch, train_acc=0.871778\n",
      "已经499个epoch, train_acc=0.875778\n",
      "已经500个epoch, train_acc=0.870222\n",
      "已经501个epoch, train_acc=0.870222\n",
      "已经502个epoch, train_acc=0.870222\n",
      "已经503个epoch, train_acc=0.870222\n",
      "已经504个epoch, train_acc=0.870222\n",
      "已经505个epoch, train_acc=0.873889\n",
      "已经506个epoch, train_acc=0.873889\n",
      "已经507个epoch, train_acc=0.873889\n",
      "已经508个epoch, train_acc=0.873889\n",
      "已经509个epoch, train_acc=0.873889\n",
      "已经510个epoch, train_acc=0.873889\n",
      "已经511个epoch, train_acc=0.873889\n",
      "已经512个epoch, train_acc=0.873889\n",
      "已经513个epoch, train_acc=0.873889\n",
      "已经514个epoch, train_acc=0.873889\n",
      "已经515个epoch, train_acc=0.873889\n",
      "已经516个epoch, train_acc=0.873889\n",
      "已经517个epoch, train_acc=0.849000\n",
      "已经518个epoch, train_acc=0.849000\n",
      "已经519个epoch, train_acc=0.849000\n",
      "已经520个epoch, train_acc=0.849000\n",
      "已经521个epoch, train_acc=0.849000\n",
      "已经522个epoch, train_acc=0.849000\n",
      "已经523个epoch, train_acc=0.849000\n",
      "已经524个epoch, train_acc=0.849000\n",
      "已经525个epoch, train_acc=0.849000\n",
      "已经526个epoch, train_acc=0.846667\n",
      "已经527个epoch, train_acc=0.853667\n",
      "已经528个epoch, train_acc=0.853667\n",
      "已经529个epoch, train_acc=0.853667\n",
      "已经530个epoch, train_acc=0.853667\n",
      "已经531个epoch, train_acc=0.853667\n",
      "已经532个epoch, train_acc=0.853667\n",
      "已经533个epoch, train_acc=0.849889\n",
      "已经534个epoch, train_acc=0.863222\n",
      "已经535个epoch, train_acc=0.863222\n",
      "已经536个epoch, train_acc=0.863222\n",
      "已经537个epoch, train_acc=0.863222\n",
      "已经538个epoch, train_acc=0.863222\n",
      "已经539个epoch, train_acc=0.863222\n",
      "已经540个epoch, train_acc=0.874889\n",
      "已经541个epoch, train_acc=0.874889\n",
      "已经542个epoch, train_acc=0.877000\n",
      "已经543个epoch, train_acc=0.877000\n",
      "已经544个epoch, train_acc=0.877000\n",
      "已经545个epoch, train_acc=0.877000\n",
      "已经546个epoch, train_acc=0.877000\n",
      "已经547个epoch, train_acc=0.877000\n",
      "已经548个epoch, train_acc=0.877000\n",
      "已经549个epoch, train_acc=0.866444\n",
      "已经550个epoch, train_acc=0.866444\n",
      "已经551个epoch, train_acc=0.866444\n",
      "已经552个epoch, train_acc=0.866444\n",
      "已经553个epoch, train_acc=0.866444\n",
      "已经554个epoch, train_acc=0.870111\n",
      "已经555个epoch, train_acc=0.870111\n",
      "已经556个epoch, train_acc=0.870111\n",
      "已经557个epoch, train_acc=0.870111\n",
      "已经558个epoch, train_acc=0.870111\n",
      "已经559个epoch, train_acc=0.870111\n",
      "已经560个epoch, train_acc=0.870111\n",
      "已经561个epoch, train_acc=0.870111\n",
      "已经562个epoch, train_acc=0.870111\n",
      "已经563个epoch, train_acc=0.870111\n",
      "已经564个epoch, train_acc=0.870111\n",
      "已经565个epoch, train_acc=0.870111\n",
      "已经566个epoch, train_acc=0.873444\n",
      "已经567个epoch, train_acc=0.873444\n",
      "已经568个epoch, train_acc=0.874889\n",
      "已经569个epoch, train_acc=0.874889\n",
      "已经570个epoch, train_acc=0.874889\n",
      "已经571个epoch, train_acc=0.874889\n",
      "已经572个epoch, train_acc=0.880333\n",
      "已经573个epoch, train_acc=0.880333\n",
      "已经574个epoch, train_acc=0.880333\n",
      "已经575个epoch, train_acc=0.880333\n",
      "已经576个epoch, train_acc=0.882556\n",
      "已经577个epoch, train_acc=0.882556\n",
      "已经578个epoch, train_acc=0.882556\n",
      "已经579个epoch, train_acc=0.882556\n",
      "已经580个epoch, train_acc=0.881111\n",
      "已经581个epoch, train_acc=0.881111\n",
      "已经582个epoch, train_acc=0.881111\n",
      "已经583个epoch, train_acc=0.881111\n",
      "已经584个epoch, train_acc=0.881111\n",
      "已经585个epoch, train_acc=0.885333\n",
      "已经586个epoch, train_acc=0.885333\n",
      "已经587个epoch, train_acc=0.885333\n",
      "已经588个epoch, train_acc=0.885333\n",
      "已经589个epoch, train_acc=0.885333\n",
      "已经590个epoch, train_acc=0.885778\n",
      "已经591个epoch, train_acc=0.885778\n",
      "已经592个epoch, train_acc=0.885778\n",
      "已经593个epoch, train_acc=0.885778\n",
      "已经594个epoch, train_acc=0.885778\n",
      "已经595个epoch, train_acc=0.885778\n",
      "已经596个epoch, train_acc=0.885778\n",
      "已经597个epoch, train_acc=0.883222\n",
      "已经598个epoch, train_acc=0.883222\n",
      "已经599个epoch, train_acc=0.883222\n",
      "已经600个epoch, train_acc=0.883222\n",
      "已经601个epoch, train_acc=0.885333\n",
      "已经602个epoch, train_acc=0.885333\n",
      "已经603个epoch, train_acc=0.885333\n",
      "已经604个epoch, train_acc=0.885333\n",
      "已经605个epoch, train_acc=0.885333\n",
      "已经606个epoch, train_acc=0.885333\n",
      "已经607个epoch, train_acc=0.885333\n",
      "已经608个epoch, train_acc=0.885333\n",
      "已经609个epoch, train_acc=0.885333\n",
      "已经610个epoch, train_acc=0.885333\n",
      "已经611个epoch, train_acc=0.885333\n",
      "已经612个epoch, train_acc=0.885333\n",
      "已经613个epoch, train_acc=0.885333\n",
      "已经614个epoch, train_acc=0.887222\n",
      "已经615个epoch, train_acc=0.884556\n",
      "已经616个epoch, train_acc=0.884556\n",
      "已经617个epoch, train_acc=0.884556\n",
      "已经618个epoch, train_acc=0.884556\n",
      "已经619个epoch, train_acc=0.884556\n",
      "已经620个epoch, train_acc=0.884556\n",
      "已经621个epoch, train_acc=0.884556\n",
      "已经622个epoch, train_acc=0.884556\n",
      "已经623个epoch, train_acc=0.884556\n",
      "已经624个epoch, train_acc=0.890778\n",
      "已经625个epoch, train_acc=0.890778\n",
      "已经626个epoch, train_acc=0.890778\n",
      "已经627个epoch, train_acc=0.890778\n",
      "已经628个epoch, train_acc=0.890778\n",
      "已经629个epoch, train_acc=0.890778\n",
      "已经630个epoch, train_acc=0.890778\n",
      "已经631个epoch, train_acc=0.890778\n",
      "已经632个epoch, train_acc=0.890778\n",
      "已经633个epoch, train_acc=0.890778\n",
      "已经634个epoch, train_acc=0.894000\n",
      "已经635个epoch, train_acc=0.902667\n",
      "已经636个epoch, train_acc=0.902667\n",
      "已经637个epoch, train_acc=0.902667\n",
      "已经638个epoch, train_acc=0.902667\n",
      "已经639个epoch, train_acc=0.902667\n",
      "已经640个epoch, train_acc=0.902667\n",
      "已经641个epoch, train_acc=0.902667\n",
      "已经642个epoch, train_acc=0.902667\n",
      "已经643个epoch, train_acc=0.902667\n",
      "已经644个epoch, train_acc=0.902667\n",
      "已经645个epoch, train_acc=0.903000\n",
      "已经646个epoch, train_acc=0.903000\n",
      "已经647个epoch, train_acc=0.903000\n",
      "已经648个epoch, train_acc=0.903000\n",
      "已经649个epoch, train_acc=0.903000\n",
      "已经650个epoch, train_acc=0.901778\n",
      "已经651个epoch, train_acc=0.901778\n",
      "已经652个epoch, train_acc=0.901778\n",
      "已经653个epoch, train_acc=0.901778\n",
      "已经654个epoch, train_acc=0.901778\n",
      "已经655个epoch, train_acc=0.901778\n",
      "已经656个epoch, train_acc=0.901778\n",
      "已经657个epoch, train_acc=0.901778\n",
      "已经658个epoch, train_acc=0.909111\n",
      "已经659个epoch, train_acc=0.909111\n",
      "已经660个epoch, train_acc=0.909111\n",
      "已经661个epoch, train_acc=0.909111\n",
      "已经662个epoch, train_acc=0.909111\n",
      "已经663个epoch, train_acc=0.909111\n",
      "已经664个epoch, train_acc=0.909111\n",
      "已经665个epoch, train_acc=0.909111\n",
      "已经666个epoch, train_acc=0.909111\n",
      "已经667个epoch, train_acc=0.909111\n",
      "已经668个epoch, train_acc=0.909111\n",
      "已经669个epoch, train_acc=0.909111\n",
      "已经670个epoch, train_acc=0.909111\n",
      "已经671个epoch, train_acc=0.909111\n",
      "已经672个epoch, train_acc=0.909111\n",
      "已经673个epoch, train_acc=0.909111\n",
      "已经674个epoch, train_acc=0.909111\n",
      "已经675个epoch, train_acc=0.906778\n",
      "已经676个epoch, train_acc=0.906778\n",
      "已经677个epoch, train_acc=0.906778\n",
      "已经678个epoch, train_acc=0.906778\n",
      "已经679个epoch, train_acc=0.906778\n",
      "已经680个epoch, train_acc=0.906778\n",
      "已经681个epoch, train_acc=0.906778\n",
      "已经682个epoch, train_acc=0.906778\n",
      "已经683个epoch, train_acc=0.906778\n",
      "已经684个epoch, train_acc=0.906778\n",
      "已经685个epoch, train_acc=0.906778\n",
      "已经686个epoch, train_acc=0.897778\n",
      "已经687个epoch, train_acc=0.897778\n",
      "已经688个epoch, train_acc=0.897778\n",
      "已经689个epoch, train_acc=0.894333\n",
      "已经690个epoch, train_acc=0.894333\n",
      "已经691个epoch, train_acc=0.895111\n",
      "已经692个epoch, train_acc=0.895111\n",
      "已经693个epoch, train_acc=0.895111\n",
      "已经694个epoch, train_acc=0.895111\n",
      "已经695个epoch, train_acc=0.895111\n",
      "已经696个epoch, train_acc=0.881000\n",
      "已经697个epoch, train_acc=0.881000\n",
      "已经698个epoch, train_acc=0.881000\n",
      "已经699个epoch, train_acc=0.882889\n",
      "已经700个epoch, train_acc=0.882889\n",
      "已经701个epoch, train_acc=0.882889\n",
      "已经702个epoch, train_acc=0.882889\n",
      "已经703个epoch, train_acc=0.882889\n",
      "已经704个epoch, train_acc=0.882889\n",
      "已经705个epoch, train_acc=0.882889\n",
      "已经706个epoch, train_acc=0.882889\n",
      "已经707个epoch, train_acc=0.882889\n",
      "已经708个epoch, train_acc=0.882889\n",
      "已经709个epoch, train_acc=0.882889\n",
      "已经710个epoch, train_acc=0.882889\n",
      "已经711个epoch, train_acc=0.882889\n",
      "已经712个epoch, train_acc=0.882889\n",
      "已经713个epoch, train_acc=0.882889\n",
      "已经714个epoch, train_acc=0.882889\n",
      "已经715个epoch, train_acc=0.882889\n",
      "已经716个epoch, train_acc=0.882889\n",
      "已经717个epoch, train_acc=0.882889\n",
      "已经718个epoch, train_acc=0.882889\n",
      "已经719个epoch, train_acc=0.882889\n",
      "已经720个epoch, train_acc=0.882889\n",
      "已经721个epoch, train_acc=0.882889\n",
      "已经722个epoch, train_acc=0.882889\n",
      "已经723个epoch, train_acc=0.882889\n",
      "已经724个epoch, train_acc=0.882889\n",
      "已经725个epoch, train_acc=0.882889\n",
      "已经726个epoch, train_acc=0.882889\n",
      "已经727个epoch, train_acc=0.882889\n",
      "已经728个epoch, train_acc=0.873000\n",
      "已经729个epoch, train_acc=0.873000\n",
      "已经730个epoch, train_acc=0.873000\n",
      "已经731个epoch, train_acc=0.873000\n",
      "已经732个epoch, train_acc=0.873000\n",
      "已经733个epoch, train_acc=0.873778\n",
      "已经734个epoch, train_acc=0.873778\n",
      "已经735个epoch, train_acc=0.873778\n",
      "已经736个epoch, train_acc=0.878000\n",
      "已经737个epoch, train_acc=0.873333\n",
      "已经738个epoch, train_acc=0.873333\n",
      "已经739个epoch, train_acc=0.873333\n",
      "已经740个epoch, train_acc=0.873333\n",
      "已经741个epoch, train_acc=0.873333\n",
      "已经742个epoch, train_acc=0.873333\n",
      "已经743个epoch, train_acc=0.873333\n",
      "已经744个epoch, train_acc=0.873333\n",
      "已经745个epoch, train_acc=0.873444\n",
      "已经746个epoch, train_acc=0.873444\n",
      "已经747个epoch, train_acc=0.868889\n",
      "已经748个epoch, train_acc=0.874111\n",
      "已经749个epoch, train_acc=0.874111\n",
      "已经750个epoch, train_acc=0.874111\n",
      "已经751个epoch, train_acc=0.874111\n",
      "已经752个epoch, train_acc=0.874111\n",
      "已经753个epoch, train_acc=0.874111\n",
      "已经754个epoch, train_acc=0.874111\n",
      "已经755个epoch, train_acc=0.874111\n",
      "已经756个epoch, train_acc=0.874111\n",
      "已经757个epoch, train_acc=0.871667\n",
      "已经758个epoch, train_acc=0.871667\n",
      "已经759个epoch, train_acc=0.871667\n",
      "已经760个epoch, train_acc=0.871667\n",
      "已经761个epoch, train_acc=0.871667\n",
      "已经762个epoch, train_acc=0.871667\n",
      "已经763个epoch, train_acc=0.871667\n",
      "已经764个epoch, train_acc=0.871667\n",
      "已经765个epoch, train_acc=0.874111\n",
      "已经766个epoch, train_acc=0.874111\n",
      "已经767个epoch, train_acc=0.874111\n",
      "已经768个epoch, train_acc=0.873444\n",
      "已经769个epoch, train_acc=0.873444\n",
      "已经770个epoch, train_acc=0.873444\n",
      "已经771个epoch, train_acc=0.873444\n",
      "已经772个epoch, train_acc=0.873444\n",
      "已经773个epoch, train_acc=0.873444\n",
      "已经774个epoch, train_acc=0.873444\n",
      "已经775个epoch, train_acc=0.873444\n",
      "已经776个epoch, train_acc=0.873444\n",
      "已经777个epoch, train_acc=0.873444\n",
      "已经778个epoch, train_acc=0.873444\n",
      "已经779个epoch, train_acc=0.873444\n",
      "已经780个epoch, train_acc=0.873444\n",
      "已经781个epoch, train_acc=0.873444\n",
      "已经782个epoch, train_acc=0.873444\n",
      "已经783个epoch, train_acc=0.873444\n",
      "已经784个epoch, train_acc=0.876778\n",
      "已经785个epoch, train_acc=0.876778\n",
      "已经786个epoch, train_acc=0.876778\n",
      "已经787个epoch, train_acc=0.876778\n",
      "已经788个epoch, train_acc=0.876778\n",
      "已经789个epoch, train_acc=0.876778\n",
      "已经790个epoch, train_acc=0.876778\n",
      "已经791个epoch, train_acc=0.876778\n",
      "已经792个epoch, train_acc=0.875111\n",
      "已经793个epoch, train_acc=0.875111\n",
      "已经794个epoch, train_acc=0.875111\n",
      "已经795个epoch, train_acc=0.875111\n",
      "已经796个epoch, train_acc=0.875111\n",
      "已经797个epoch, train_acc=0.875111\n",
      "已经798个epoch, train_acc=0.881111\n",
      "已经799个epoch, train_acc=0.881111\n",
      "已经800个epoch, train_acc=0.881111\n",
      "已经801个epoch, train_acc=0.881111\n",
      "已经802个epoch, train_acc=0.885222\n",
      "已经803个epoch, train_acc=0.885222\n",
      "已经804个epoch, train_acc=0.885222\n",
      "已经805个epoch, train_acc=0.885222\n",
      "已经806个epoch, train_acc=0.885222\n",
      "已经807个epoch, train_acc=0.885222\n",
      "已经808个epoch, train_acc=0.885222\n",
      "已经809个epoch, train_acc=0.885222\n",
      "已经810个epoch, train_acc=0.885222\n",
      "已经811个epoch, train_acc=0.885222\n",
      "已经812个epoch, train_acc=0.885222\n",
      "已经813个epoch, train_acc=0.885222\n",
      "已经814个epoch, train_acc=0.885222\n",
      "已经815个epoch, train_acc=0.885222\n",
      "已经816个epoch, train_acc=0.885222\n",
      "已经817个epoch, train_acc=0.885222\n",
      "已经818个epoch, train_acc=0.885222\n",
      "已经819个epoch, train_acc=0.885222\n",
      "已经820个epoch, train_acc=0.885222\n",
      "已经821个epoch, train_acc=0.885222\n",
      "已经822个epoch, train_acc=0.885222\n",
      "已经823个epoch, train_acc=0.885222\n",
      "已经824个epoch, train_acc=0.885222\n",
      "已经825个epoch, train_acc=0.885222\n",
      "已经826个epoch, train_acc=0.885556\n",
      "已经827个epoch, train_acc=0.890333\n",
      "已经828个epoch, train_acc=0.886667\n",
      "已经829个epoch, train_acc=0.886667\n",
      "已经830个epoch, train_acc=0.886667\n",
      "已经831个epoch, train_acc=0.886778\n",
      "已经832个epoch, train_acc=0.886778\n",
      "已经833个epoch, train_acc=0.886778\n",
      "已经834个epoch, train_acc=0.886778\n",
      "已经835个epoch, train_acc=0.886778\n",
      "已经836个epoch, train_acc=0.886778\n",
      "已经837个epoch, train_acc=0.886778\n",
      "已经838个epoch, train_acc=0.891889\n",
      "已经839个epoch, train_acc=0.891889\n",
      "已经840个epoch, train_acc=0.891889\n",
      "已经841个epoch, train_acc=0.891889\n",
      "已经842个epoch, train_acc=0.896222\n",
      "已经843个epoch, train_acc=0.896222\n",
      "已经844个epoch, train_acc=0.896222\n",
      "已经845个epoch, train_acc=0.896222\n",
      "已经846个epoch, train_acc=0.896222\n",
      "已经847个epoch, train_acc=0.896222\n",
      "已经848个epoch, train_acc=0.896222\n",
      "已经849个epoch, train_acc=0.896222\n",
      "已经850个epoch, train_acc=0.896222\n",
      "已经851个epoch, train_acc=0.896222\n",
      "已经852个epoch, train_acc=0.896222\n",
      "已经853个epoch, train_acc=0.896222\n",
      "已经854个epoch, train_acc=0.896222\n",
      "已经855个epoch, train_acc=0.896222\n",
      "已经856个epoch, train_acc=0.896222\n",
      "已经857个epoch, train_acc=0.896222\n",
      "已经858个epoch, train_acc=0.896222\n",
      "已经859个epoch, train_acc=0.896222\n",
      "已经860个epoch, train_acc=0.896222\n",
      "已经861个epoch, train_acc=0.896222\n",
      "已经862个epoch, train_acc=0.896222\n",
      "已经863个epoch, train_acc=0.896222\n",
      "已经864个epoch, train_acc=0.896222\n",
      "已经865个epoch, train_acc=0.897778\n",
      "已经866个epoch, train_acc=0.897778\n",
      "已经867个epoch, train_acc=0.897778\n",
      "已经868个epoch, train_acc=0.897778\n",
      "已经869个epoch, train_acc=0.897778\n",
      "已经870个epoch, train_acc=0.897778\n",
      "已经871个epoch, train_acc=0.897778\n",
      "已经872个epoch, train_acc=0.897778\n",
      "已经873个epoch, train_acc=0.897778\n",
      "已经874个epoch, train_acc=0.895333\n",
      "已经875个epoch, train_acc=0.895333\n",
      "已经876个epoch, train_acc=0.894889\n",
      "已经877个epoch, train_acc=0.894889\n",
      "已经878个epoch, train_acc=0.900111\n",
      "已经879个epoch, train_acc=0.900111\n",
      "已经880个epoch, train_acc=0.900111\n",
      "已经881个epoch, train_acc=0.900111\n",
      "已经882个epoch, train_acc=0.900111\n",
      "已经883个epoch, train_acc=0.900111\n",
      "已经884个epoch, train_acc=0.900111\n",
      "已经885个epoch, train_acc=0.900111\n",
      "已经886个epoch, train_acc=0.900111\n",
      "已经887个epoch, train_acc=0.900111\n",
      "已经888个epoch, train_acc=0.900111\n",
      "已经889个epoch, train_acc=0.900111\n",
      "已经890个epoch, train_acc=0.900111\n",
      "已经891个epoch, train_acc=0.900111\n",
      "已经892个epoch, train_acc=0.900111\n",
      "已经893个epoch, train_acc=0.900111\n",
      "已经894个epoch, train_acc=0.900111\n",
      "已经895个epoch, train_acc=0.900111\n",
      "已经896个epoch, train_acc=0.900111\n",
      "已经897个epoch, train_acc=0.900111\n",
      "已经898个epoch, train_acc=0.898889\n",
      "已经899个epoch, train_acc=0.898889\n",
      "已经900个epoch, train_acc=0.898889\n",
      "已经901个epoch, train_acc=0.898889\n",
      "已经902个epoch, train_acc=0.898889\n",
      "已经903个epoch, train_acc=0.898889\n",
      "已经904个epoch, train_acc=0.898889\n",
      "已经905个epoch, train_acc=0.898889\n",
      "已经906个epoch, train_acc=0.898889\n",
      "已经907个epoch, train_acc=0.896667\n",
      "已经908个epoch, train_acc=0.896667\n",
      "已经909个epoch, train_acc=0.896667\n",
      "已经910个epoch, train_acc=0.896667\n",
      "已经911个epoch, train_acc=0.896667\n",
      "已经912个epoch, train_acc=0.896667\n",
      "已经913个epoch, train_acc=0.887222\n",
      "已经914个epoch, train_acc=0.887222\n",
      "已经915个epoch, train_acc=0.887222\n",
      "已经916个epoch, train_acc=0.887222\n",
      "已经917个epoch, train_acc=0.887222\n",
      "已经918个epoch, train_acc=0.887222\n",
      "已经919个epoch, train_acc=0.887222\n",
      "已经920个epoch, train_acc=0.887222\n",
      "已经921个epoch, train_acc=0.887222\n",
      "已经922个epoch, train_acc=0.887222\n",
      "已经923个epoch, train_acc=0.889222\n",
      "已经924个epoch, train_acc=0.888444\n",
      "已经925个epoch, train_acc=0.888778\n",
      "已经926个epoch, train_acc=0.888778\n",
      "已经927个epoch, train_acc=0.888778\n",
      "已经928个epoch, train_acc=0.888778\n",
      "已经929个epoch, train_acc=0.888778\n",
      "已经930个epoch, train_acc=0.888778\n",
      "已经931个epoch, train_acc=0.888778\n",
      "已经932个epoch, train_acc=0.888778\n",
      "已经933个epoch, train_acc=0.893333\n",
      "已经934个epoch, train_acc=0.893333\n",
      "已经935个epoch, train_acc=0.893333\n",
      "已经936个epoch, train_acc=0.893333\n",
      "已经937个epoch, train_acc=0.893333\n",
      "已经938个epoch, train_acc=0.893333\n",
      "已经939个epoch, train_acc=0.893333\n",
      "已经940个epoch, train_acc=0.893333\n",
      "已经941个epoch, train_acc=0.893333\n",
      "已经942个epoch, train_acc=0.893333\n",
      "已经943个epoch, train_acc=0.893333\n",
      "已经944个epoch, train_acc=0.893333\n",
      "已经945个epoch, train_acc=0.893333\n",
      "已经946个epoch, train_acc=0.893333\n",
      "已经947个epoch, train_acc=0.893333\n",
      "已经948个epoch, train_acc=0.893333\n",
      "已经949个epoch, train_acc=0.893333\n",
      "已经950个epoch, train_acc=0.893333\n",
      "已经951个epoch, train_acc=0.893333\n",
      "已经952个epoch, train_acc=0.893333\n",
      "已经953个epoch, train_acc=0.893333\n",
      "已经954个epoch, train_acc=0.893333\n",
      "已经955个epoch, train_acc=0.893333\n",
      "已经956个epoch, train_acc=0.895000\n",
      "已经957个epoch, train_acc=0.895000\n",
      "已经958个epoch, train_acc=0.895000\n",
      "已经959个epoch, train_acc=0.895000\n",
      "已经960个epoch, train_acc=0.895000\n",
      "已经961个epoch, train_acc=0.888778\n",
      "已经962个epoch, train_acc=0.888778\n",
      "已经963个epoch, train_acc=0.888778\n",
      "已经964个epoch, train_acc=0.888778\n",
      "已经965个epoch, train_acc=0.888778\n",
      "已经966个epoch, train_acc=0.888889\n",
      "已经967个epoch, train_acc=0.888889\n",
      "已经968个epoch, train_acc=0.888889\n",
      "已经969个epoch, train_acc=0.888889\n",
      "已经970个epoch, train_acc=0.888889\n",
      "已经971个epoch, train_acc=0.888889\n",
      "已经972个epoch, train_acc=0.888889\n",
      "已经973个epoch, train_acc=0.888889\n",
      "已经974个epoch, train_acc=0.888889\n",
      "已经975个epoch, train_acc=0.888889\n",
      "已经976个epoch, train_acc=0.888889\n",
      "已经977个epoch, train_acc=0.888889\n",
      "已经978个epoch, train_acc=0.888889\n",
      "已经979个epoch, train_acc=0.888889\n",
      "已经980个epoch, train_acc=0.888889\n",
      "已经981个epoch, train_acc=0.888889\n",
      "已经982个epoch, train_acc=0.888889\n",
      "已经983个epoch, train_acc=0.892333\n",
      "已经984个epoch, train_acc=0.894111\n",
      "已经985个epoch, train_acc=0.894111\n",
      "已经986个epoch, train_acc=0.894111\n",
      "已经987个epoch, train_acc=0.894111\n",
      "已经988个epoch, train_acc=0.894111\n",
      "已经989个epoch, train_acc=0.894111\n",
      "已经990个epoch, train_acc=0.894111\n",
      "已经991个epoch, train_acc=0.894111\n",
      "已经992个epoch, train_acc=0.894111\n",
      "已经993个epoch, train_acc=0.894111\n",
      "已经994个epoch, train_acc=0.894111\n",
      "已经995个epoch, train_acc=0.894111\n",
      "已经996个epoch, train_acc=0.894111\n",
      "已经997个epoch, train_acc=0.894111\n",
      "已经998个epoch, train_acc=0.894111\n",
      "已经999个epoch, train_acc=0.894111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate data\n",
    "X_data, y_data, mislabel = generate_data(20, 10000) \n",
    "# print(X_data)\n",
    "# print(y_data)\n",
    "\n",
    "# split data\n",
    "X_train = X_data[0:9000]\n",
    "y_train = y_data[0:9000]\n",
    "X_test = X_data[9001:]\n",
    "y_test = y_data[9001:]\n",
    "\n",
    "# constrcut model and train (remember record time)\n",
    "model2 = SVM2(20, maxiter=1000, C=1)\n",
    "model2.fit(X_train, y_train, val_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc = 0.8941111111111111\n",
      "test acc = 0.8968968968968969\n",
      "错误率曲线如下：\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make prediction\n",
    "# pred = model1.predict()\n",
    "\n",
    "# predict and calculate acc\n",
    "train_acc = model2.score(X_train, y_train, metric='acc')\n",
    "test_acc = model2.score(X_test, y_test, metric='acc')\n",
    "print(\"train acc = {0}\".format(train_acc))\n",
    "print(\"test acc = {0}\".format(test_acc))\n",
    "print(\"错误率曲线如下：\")\n",
    "model2.plot_learning_curve()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用 sklearn 库进行对比（跑完大概需要 30s）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianglei/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准库准确率： 0.960960960960961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import metrics\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "prediction = model.predict(X_test)\n",
    "print(\"标准库准确率：\", metrics.accuracy_score(prediction, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "10b64fb600cf202ef54af29224834694bcb93f28bca7af7234f805e5e67a81f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
